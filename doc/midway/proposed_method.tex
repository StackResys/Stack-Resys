
\subsection{Naive Bayes}
How it works

How it works in our project

the Advantage.

the disadvantage.
\subsection{Logistic Regression}

\IncMargin{1em}
\begin{algorithm}
\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\Input{Training set $T=\{t_1,...t_n\}$, constant $\eta$, converge threshold $\varepsilon$}
\Output{Weight matrix $W$}
\BlankLine
Initialize all $w_{ij} \in W$ to 0\;
$isConverge \leftarrow false$\;
\While{$isConverge = false$}{
	\ForEach{$w_{ij} \in W$}{
		\ForEach{$t_l \in T$}{
			$jump_{ij} \leftarrow 0$\;
			Calculate $d=X_{i}^{l}(\delta (Y^{l}=y_{j})-\hat{P}(Y^{l}=y_{j}|X^{l},W))$\;
			$jump_{ij} \leftarrow \eta * d$\;
		}
		$w_{ij} \leftarrow w_{ij} + jump_{ij}$\;
	}
	\If{$\forall jump_{ij} \rightarrow jump_{ij} < \varepsilon$}{
		$isConverge \leftarrow true$\;
	}
}
\Return $W$\;

\caption{Logistic Regression}\label{algo_disjdecomp}
\end{algorithm}\DecMargin{1em}

\subsection{SVM}
